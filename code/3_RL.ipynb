{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rl import RL, train\n",
    "#from data import DataLoader, make_data_loaders\n",
    "#from rl import RL, DQNExperiment, train\n",
    "import os, yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "if os.getcwd()[-4:] == \"code\":\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "import os, math, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./code/params.yaml\")) as f:\n",
    "        params = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11569 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 258/11569 [00:03<02:29, 75.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m loader_train, loader_validation \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminibatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrolling_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdischarge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 109\u001b[0m, in \u001b[0;36mmake_data_loaders\u001b[1;34m(train_data, validation_data, rng, device, minibatch_size, rolling_size, type)\u001b[0m\n\u001b[0;32m    107\u001b[0m loader_train \u001b[38;5;241m=\u001b[39m DataLoader(train_data, rng, device, minibatch_size, rolling_size, \u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m    108\u001b[0m loader_validation \u001b[38;5;241m=\u001b[39m DataLoader(validation_data, rng, device, minibatch_size, rolling_size, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m \u001b[43mloader_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_transition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m loader_validation\u001b[38;5;241m.\u001b[39mmake_transition()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader_train, loader_validation\n",
      "Cell \u001b[1;32mIn[26], line 70\u001b[0m, in \u001b[0;36mDataLoader.make_transition\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m][count] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj\u001b[39m\u001b[38;5;124m'\u001b[39m][traj][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m][t\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrolling_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:t\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrolling_size]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m][count] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj\u001b[39m\u001b[38;5;124m'\u001b[39m][traj][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m][t\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrolling_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:t\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrolling_size]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_s\u001b[39m\u001b[38;5;124m'\u001b[39m][count] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling_size\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterminal\u001b[39m\u001b[38;5;124m'\u001b[39m][count] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     72\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\frame.py:11360\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11286\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11289\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11290\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11358\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1794\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1795\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(params['random_seed'])\n",
    "torch.manual_seed(params['random_seed'])\n",
    "rng = np.random.RandomState(params['random_seed'])\n",
    "\n",
    "loader_train, loader_validation = make_data_loaders(params['train'], params['val'], rng, params['device'],params['minibatch_size'],params['rolling_size'],type='discharge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Experiment\n",
      "Running experiment (training Q-Networks)\n",
      "\n",
      "Minibatch learning within epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.shape: torch.Size([64, 11])\n",
      "a.shape: torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAHS\\AppData\\Local\\Temp\\ipykernel_197636\\99138351.py:124: UserWarning: Using a target size (torch.Size([64, 64])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.smooth_l1_loss(q_pred, bellman_target)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_validation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 270\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, rng, loader_train, loader_validation)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''with open(os.path.join(expt.storage_rl, 'config_exp.yaml'), 'w') as y:\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m        yaml.safe_dump(params, y)  # saving new params for future reference'''\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning experiment (training Q-Networks)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 270\u001b[0m \u001b[43mexpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexp_num_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Q-Networks finished successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 218\u001b[0m, in \u001b[0;36mDQNExperiment.do_epochs\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    216\u001b[0m     s, actions, rewards, next_s, terminals, epoch_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader_train\u001b[38;5;241m.\u001b[39mget_next_minibatch()\n\u001b[0;32m    217\u001b[0m     epoch_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s)\n\u001b[1;32m--> 218\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader_train\u001b[38;5;241m.\u001b[39mreset(shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[38], line 166\u001b[0m, in \u001b[0;36mRL.learn\u001b[1;34m(self, s, a, r, s2, term)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, a, r, s2, term):\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Learning from one minibatch \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_counter \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_freq:\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork)\n",
      "Cell \u001b[1;32mIn[38], line 126\u001b[0m, in \u001b[0;36mRL.train_on_batch\u001b[1;34m(self, s, a, r, s2, t)\u001b[0m\n\u001b[0;32m    124\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msmooth_l1_loss(q_pred, bellman_target)            \n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 126\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "train(params, rng, loader_train, loader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "import os, math, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, df, rng, device, minibatch_size, rolling_size, type):\n",
    "        self.df = pd.read_parquet(df)\n",
    "        self.dict = {}\n",
    "        self.rng = rng\n",
    "        self.device = device\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rolling_size = rolling_size\n",
    "        self.type = type\n",
    "\n",
    "        self.transition = {}\n",
    "        self.index_transition = None\n",
    "        self.index_pos_last = []\n",
    "        self.index_neg_last = []\n",
    "        self.data_size = None\n",
    "\n",
    "        self.transitions_head = None\n",
    "        self.epoch_finished = True  # to enforce reset() before use\n",
    "        self.num_minibatches_epoch = None\n",
    "\n",
    "        self.drop_smaller_than_minibatch = False\n",
    "\n",
    "    def reset(self, shuffle):\n",
    "        if shuffle:\n",
    "            self.rng.shuffle(self.index_transition)\n",
    "        self.transitions_head = 0\n",
    "        self.epoch_finished = False\n",
    "        self.num_minibatches_epoch = int(np.floor(self.data_size / self.minibatch_size)) + int(1 - self.drop_smaller_than_minibatch)\n",
    "\n",
    "    def make_transition(self):\n",
    "        self.dict['traj'] = {}\n",
    "        self.transition['s'] = {}\n",
    "        self.transition['a'] = {}\n",
    "        self.transition['r'] = {}\n",
    "        self.transition['next_s'] = {}\n",
    "        self.transition['terminal'] = {}\n",
    "        self.transition['pos_traj'] = []\n",
    "        self.transition['neg_traj'] = []\n",
    "        count = 0\n",
    "        s = [x for x in self.df.columns if x[:2]=='s:']\n",
    "        a = [x for x in self.df.columns if x[:2]=='a:']\n",
    "        r = [x for x in self.df.columns if x==('r:'+self.type)]\n",
    "\n",
    "        for traj in tqdm(self.df.traj.unique()):\n",
    "            df_i = self.df[self.df['traj']==traj].sort_values(by='step')\n",
    "            self.dict['traj'][traj] = {'s': [], 'a': [], 'r': []}\n",
    "            self.dict['traj'][traj]['s'] = df_i[s]\n",
    "            self.dict['traj'][traj]['a'] = df_i[a]\n",
    "            self.dict['traj'][traj]['r'] = df_i[r]\n",
    "            if sum(df_i[r].values) > 0:\n",
    "                self.transition['pos_traj'].append(traj)\n",
    "            else :\n",
    "                self.transition['neg_traj'].append(traj)\n",
    "\n",
    "            t_len = len(self.dict['traj'][traj]['s']) - self.rolling_size - 1\n",
    "            for t in range(t_len):\n",
    "                self.transition['s'][count] = self.dict['traj'][traj]['s'][t:t+self.rolling_size].values.flatten()\n",
    "                self.transition['a'][count] = self.dict['traj'][traj]['a'][t+self.rolling_size-1:t+self.rolling_size].values.flatten()\n",
    "                self.transition['r'][count] = self.dict['traj'][traj]['r'][t+self.rolling_size-1:t+self.rolling_size].values.flatten()\n",
    "                self.transition['next_s'][count] = self.dict['traj'][traj]['s'][t+1:t+self.rolling_size+1].values.flatten()\n",
    "                self.transition['terminal'][count] = 0\n",
    "                count += 1\n",
    "            tlast = t_len\n",
    "            self.transition['s'][count] = self.dict['traj'][traj]['s'][tlast:tlast+self.rolling_size].values.flatten()\n",
    "            self.transition['a'][count] = self.dict['traj'][traj]['a'][tlast+self.rolling_size-1:tlast+self.rolling_size].values.flatten()\n",
    "            self.transition['r'][count] = self.dict['traj'][traj]['r'][tlast+self.rolling_size-1:tlast+self.rolling_size].values.flatten()\n",
    "            self.transition['next_s'][count] = self.dict['traj'][traj]['s'][tlast+1:tlast+self.rolling_size+1].values.flatten()\n",
    "            self.transition['terminal'][count] = 1\n",
    "            #if traj in self.encoded_data['pos_traj']:self.pos_last.append(count)\n",
    "            #else : self.neg_last.append(count)\n",
    "            count += 1\n",
    "        self.data_size = count\n",
    "        self.index_transition = np.arange(self.data_size)\n",
    "\n",
    "    def get_next_minibatch(self):\n",
    "        if self.epoch_finished == True:\n",
    "            print('Epoch finished, please call reset() method before next call to get_next_minibatch()')\n",
    "            return None\n",
    "        # Getting data from dictionaries\n",
    "        minibatch_main_index_list = list(self.index_transition[self.transitions_head:self.transitions_head + self.minibatch_size])\n",
    "\n",
    "        minibatch_index_list = minibatch_main_index_list\n",
    "        get_from_dict = operator.itemgetter(*minibatch_index_list)\n",
    "        s_minibatch = get_from_dict(self.transition['s'])\n",
    "        actions_minibatch = get_from_dict(self.transition['a'])\n",
    "        rewards_minibatch = get_from_dict(self.transition['r'])\n",
    "        next_s_minibatch = get_from_dict(self.transition['next_s'])\n",
    "        terminals_minibatch = get_from_dict(self.transition['terminal'])\n",
    "        # Updating current data head\n",
    "        self.transitions_head += self.minibatch_size\n",
    "        self.epoch_finished = self.transitions_head + self.drop_smaller_than_minibatch*self.minibatch_size >= self.data_size\n",
    "        return s_minibatch, actions_minibatch, rewards_minibatch, next_s_minibatch, terminals_minibatch, self.epoch_finished\n",
    "\n",
    "\n",
    "def make_data_loaders(train_data, validation_data, rng, device, minibatch_size, rolling_size, type):\n",
    "    # Note that the loaders will be reset in Experiment\n",
    "    loader_train = DataLoader(train_data, rng, device, minibatch_size, rolling_size, type)\n",
    "    loader_validation = DataLoader(validation_data, rng, device, minibatch_size, rolling_size, type)\n",
    "    loader_train.make_transition()\n",
    "    loader_validation.make_transition()\n",
    "    return loader_train, loader_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, rolling_size, nb_actions=None):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        self.state_dim = state_dim * rolling_size\n",
    "        self.nb_actions = nb_actions\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.nb_actions)\n",
    "        )\n",
    "        self.fc.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class IMVFullLSTM(torch.jit.ScriptModule):\n",
    "    __constants__ = [\"n_units\", \"state_dim\"]\n",
    "    def __init__(self, state_dim, nb_actions, n_units, init_std=0.02):\n",
    "        super().__init__()\n",
    "        self.U_j = nn.Parameter(torch.randn(state_dim, 1, n_units)*init_std)\n",
    "        self.W_j = nn.Parameter(torch.randn(state_dim, n_units, n_units)*init_std)\n",
    "        self.b_j = nn.Parameter(torch.randn(state_dim, n_units)*init_std)\n",
    "        self.W_i = nn.Linear(state_dim*(n_units+1), state_dim*n_units)\n",
    "        self.W_f = nn.Linear(state_dim*(n_units+1), state_dim*n_units)\n",
    "        self.W_o = nn.Linear(state_dim*(n_units+1), state_dim*n_units)\n",
    "        self.F_alpha_n = nn.Parameter(torch.randn(state_dim, n_units, 1)*init_std)\n",
    "        self.F_alpha_n_b = nn.Parameter(torch.randn(state_dim, 1)*init_std)\n",
    "        self.F_beta = nn.Linear(2*n_units, 1)\n",
    "        self.Phi = nn.Linear(2*n_units, nb_actions)\n",
    "        self.n_units = n_units\n",
    "        self.state_dim = state_dim\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        h_tilda_t = torch.zeros(x.shape[0], self.state_dim, self.n_units).cpu()\n",
    "        c_t = torch.zeros(x.shape[0], self.state_dim*self.n_units).cpu()\n",
    "        outputs = torch.jit.annotate(List[Tensor], [])\n",
    "        for t in range(x.shape[1]):\n",
    "            # eq 1\n",
    "            j_tilda_t = torch.tanh(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_j) + \\\n",
    "                                   torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_j) + self.b_j)\n",
    "            inp =  torch.cat([x[:, t, :], h_tilda_t.view(h_tilda_t.shape[0], -1)], dim=1)\n",
    "            # eq 2\n",
    "            i_t = torch.sigmoid(self.W_i(inp))\n",
    "            f_t = torch.sigmoid(self.W_f(inp))\n",
    "            o_t = torch.sigmoid(self.W_o(inp))\n",
    "            # eq 3\n",
    "            c_t = c_t*f_t + i_t*j_tilda_t.reshape(j_tilda_t.shape[0], -1)\n",
    "            # eq 4\n",
    "            h_tilda_t = (o_t*torch.tanh(c_t)).view(h_tilda_t.shape[0], self.state_dim, self.n_units)\n",
    "            outputs += [h_tilda_t]\n",
    "        outputs = torch.stack(outputs)\n",
    "        outputs = outputs.permute(1, 0, 2, 3)\n",
    "        # eq 8\n",
    "        alphas = torch.tanh(torch.einsum(\"btij,ijk->btik\", outputs, self.F_alpha_n) +self.F_alpha_n_b)\n",
    "        alphas = torch.exp(alphas)\n",
    "        #print('alpha.shape:',alphas.shape)\n",
    "        alphas = alphas/torch.sum(alphas, dim=1, keepdim=True)\n",
    "        #print('alpha2.shape:',alphas.shape)\n",
    "        g_n = torch.sum(alphas*outputs, dim=1)\n",
    "        #print('g_n.shape:',g_n.shape)\n",
    "        hg = torch.cat([g_n, h_tilda_t], dim=2)\n",
    "        #print('hg.shape:',hg.shape)\n",
    "        mu = self.Phi(hg)\n",
    "        #print('mu.shape:',mu.shape)\n",
    "        betas = torch.tanh(self.F_beta(hg))\n",
    "        betas = torch.exp(betas)\n",
    "        #print('betas.shape:',betas.shape)\n",
    "        betas = betas/torch.sum(betas, dim=1, keepdim=True)\n",
    "        #print('betas2.shape:',betas.shape)\n",
    "        mean = torch.sum(betas*mu, dim=1)\n",
    "        #print('mean.shape:',mean.shape)\n",
    "        return mean#, alphas, betas\n",
    "\n",
    "class RL(object):\n",
    "    def __init__(self, state_dim, rolling_size, nb_actions, n_units, gamma,\n",
    "                 learning_rate, update_freq, rng, device):\n",
    "        self.rng = rng\n",
    "        self.state_dim = state_dim\n",
    "        self.rolling_size = rolling_size\n",
    "        self.nb_actions = nb_actions\n",
    "        self.n_units = n_units\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.update_freq = update_freq\n",
    "        self.update_counter = 0\n",
    "        self.device = device\n",
    "        self.network = QNetwork(state_dim=self.state_dim, rolling_size=self.rolling_size, nb_actions=self.nb_actions)\n",
    "        self.target_network = QNetwork(state_dim=self.state_dim, rolling_size=self.rolling_size, nb_actions=self.nb_actions)\n",
    "        #self.network = IMVFullLSTM(state_dim=self.state_dim, nb_actions=self.nb_actions, n_units=self.n_units)\n",
    "        #self.target_network = IMVFullLSTM(state_dim=self.state_dim, nb_actions=self.nb_actions, n_units=self.n_units)\n",
    "        #self.weight_transfer(from_model=self.network, to_model=self.target_network)\n",
    "        self.network.to(self.device)\n",
    "        self.target_network.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=self.learning_rate, amsgrad=True)\n",
    "\n",
    "    def train_on_batch(self, s, a, r, s2, t):\n",
    "        s  = torch.FloatTensor(np.float32(s)).to(self.device)\n",
    "        s2 = torch.FloatTensor(np.float32(s2)).to(self.device)\n",
    "        a  = torch.LongTensor(np.int64(a)).to(self.device)\n",
    "        r  = torch.FloatTensor(np.float32(r)).to(self.device)\n",
    "        t  = torch.FloatTensor(np.float32(t)).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q = self.network(s).detach()\n",
    "            q2 = self.target_network(s2).detach()\n",
    "        print(\"q.shape:\",q.shape)\n",
    "        print(\"a.shape:\",a.shape)\n",
    "\n",
    "        q_pred = q.gather(1, a).squeeze(1)\n",
    "        #q_pred = q.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        q2_net = self.network(s2).detach()\n",
    "        q2_max = q2.gather(1, torch.max(q2_net, 1)[1].unsqueeze(1)).squeeze(1)\n",
    "        bellman_target = torch.clamp(r, max=1.0, min=0.0) + self.gamma * torch.clamp(q2_max.detach(), max=1.0, min=0.0) * (1 - t)\n",
    "\n",
    "        loss = F.smooth_l1_loss(q_pred, bellman_target)            \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach().cpu().numpy()\n",
    "\n",
    "    def get_loss(self, s, a, r, s2, t):\n",
    "        s  = torch.FloatTensor(np.float32(s)).to(self.device)\n",
    "        s2 = torch.FloatTensor(np.float32(s2)).to(self.device)\n",
    "        a  = torch.LongTensor(np.int64(a)).to(self.device)\n",
    "        r  = torch.FloatTensor(np.float32(r)).to(self.device)\n",
    "        t  = torch.FloatTensor(np.float32(t)).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q = self.network(s).detach()\n",
    "            q2 = self.target_network(s2).detach()\n",
    "        print(\"q:\",q.shape,q)\n",
    "        q_pred = q.gather(1, a).squeeze(1)\n",
    "        print(\"q_pred\",q_pred.shape,q_pred)\n",
    "        #q_pred = q.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        q2_net = self.network(s2).detach()\n",
    "        q2_max = q2.gather(1, torch.max(q2_net, 1)[1].unsqueeze(1)).squeeze(1)\n",
    "        bellman_target = torch.clamp(r, max=1.0, min=0.0) + self.gamma * torch.clamp(q2_max.detach(), max=1.0, min=0.0) * (1 - t)\n",
    "        print(\"bellman_target:\",bellman_target.shape,bellman_target)\n",
    "        loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "        return loss.detach().cpu().numpy()\n",
    "\n",
    "    def get_q(self, s):\n",
    "        s = torch.FloatTensor(s).to(self.device)\n",
    "        return self.network(s).detach().cpu().numpy()\n",
    "\n",
    "    def get_max_action(self, s):\n",
    "        s = torch.FloatTensor(s).to(self.device)\n",
    "        q = self.network(s).detach()\n",
    "        return q.max(1)[1].cpu().numpy()\n",
    "\n",
    "    def get_action(self, states):\n",
    "        return self.get_max_action(states)\n",
    "\n",
    "    def learn(self, s, a, r, s2, term):\n",
    "        \"\"\" Learning from one minibatch \"\"\"\n",
    "        loss = self.train_on_batch(s, a, r, s2, term)\n",
    "        if self.update_counter == self.update_freq:\n",
    "            self.target_network.load_state_dict(self.network)\n",
    "            #self.weight_transfer(self.network, self.target_network)\n",
    "            self.update_counter = 0\n",
    "        else:\n",
    "            self.update_counter += 1\n",
    "        return loss\n",
    "\n",
    "    # weight_transfer(from_model, to_model):\n",
    "        #to_model.load_state_dict(from_model.state_dict())\n",
    "\n",
    "\n",
    "class DQNExperiment(object):\n",
    "    def __init__(self, data_loader_train, data_loader_validation, q_network, saving_period, rng):\n",
    "        self.rng = rng\n",
    "        self.data_loader_train = data_loader_train\n",
    "        self.data_loader_validation = data_loader_validation\n",
    "        self.q_network = q_network\n",
    "        self.batch_num = 0\n",
    "        self.saving_period = saving_period  # after each `saving_period` epochs, the results so far will be saved.\n",
    "        '''storage_path = os.path.join(os.path.abspath(folder_location), folder_name)\n",
    "        self.storage_rl = os.path.join(storage_path, 'rl_' + self.q_network.sided_Q)\n",
    "        self.checkpoint_folder = os.path.join(storage_path, 'rl_' + self.q_network.sided_Q + '_checkpoints')\n",
    "        if not os.path.exists(self.storage_rl):\n",
    "            os.mkdir(self.storage_rl)\n",
    "        if not os.path.exists(self.checkpoint_folder):\n",
    "            os.mkdir(self.checkpoint_folder)'''\n",
    "        \n",
    "    def do_epochs(self, number):\n",
    "        '''\n",
    "        Each epoch is one iteration thorugh the entire dataset.\n",
    "        '''\n",
    "        self.curr_epoch = 0\n",
    "        self.all_epoch_steps = []\n",
    "        self.all_epoch_validation_steps = []\n",
    "        self.all_epoch_loss = []\n",
    "        self.all_epoch_validation_loss = []\n",
    "        self.data_loader_train.reset(shuffle=True)\n",
    "        self.data_loader_validation.reset(shuffle=False)\n",
    "        for epoch in range(self.curr_epoch, number):\n",
    "            print()\n",
    "            #print('>>>>> Experiment ' + 'Q-' + self.q_network.sided_Q + ' Epoch ' + str(epoch + 1) + '/' + str(number))\n",
    "            # Learn here\n",
    "            epoch_done = False\n",
    "            epoch_steps = 0\n",
    "            epoch_loss = 0\n",
    "            print('Minibatch learning within epoch')\n",
    "            bar = pyprind.ProgBar(self.data_loader_train.num_minibatches_epoch)\n",
    "            while not epoch_done:\n",
    "                s, actions, rewards, next_s, terminals, epoch_done = self.data_loader_train.get_next_minibatch()\n",
    "                epoch_steps += len(s)\n",
    "                loss = self.q_network.learn(s, actions, rewards, next_s, terminals)\n",
    "                epoch_loss += loss\n",
    "            self.data_loader_train.reset(shuffle=True)\n",
    "            self.data_loader_validation.reset(shuffle=False, pos_samples_in_minibatch=0, neg_samples_in_minibatch=0)\n",
    "            self.all_epoch_loss.append(epoch_loss/epoch_steps)\n",
    "            self.all_epoch_steps.append(epoch_steps)\n",
    "            if (epoch + 1)% self.saving_period == 0:\n",
    "                self._do_eval()\n",
    "                '''try:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'rl_network_state_dict': self.q_network.network.state_dict(),\n",
    "                        # 'rl_target_network_state_dict': self.q_network.target_network.state_dict(),\n",
    "                        # 'rl_optimizer_state_dict': self.q_network.optimizer.state_dict(),\n",
    "                        'loss': self.all_epoch_loss,\n",
    "                        'validation_loss': self.all_epoch_validation_loss,\n",
    "                        'epoch_steps': self.all_epoch_steps,\n",
    "                        'epoch_validation_steps': self.all_epoch_validation_steps,\n",
    "                    }, os.path.join(self.checkpoint_folder, 'checkpoint' + str(epoch) +'.pt'))\n",
    "                    #np.save(os.path.join(self.storage_rl, 'q_losses.npy'), np.array(self.all_epoch_loss))\n",
    "                except:\n",
    "                    print(\">>> Cannot save files. On Windows: the files might be open.\")'''\n",
    "        \n",
    "    def _do_eval(self):\n",
    "        epoch_val_steps = 0\n",
    "        epoch_val_loss = 0\n",
    "        epoch_done = False\n",
    "        bar = pyprind.ProgBar(self.data_loader_validation.num_minibatches_epoch)\n",
    "        while not epoch_done:\n",
    "            bar.update()\n",
    "            s, actions, rewards, next_s, terminals, epoch_done = self.data_loader_validation.get_next_minibatch()\n",
    "            epoch_val_steps += len(s)\n",
    "            loss = self.q_network.get_loss(s, actions, rewards, next_s, terminals)\n",
    "            epoch_val_loss += loss\n",
    "        self.all_epoch_validation_loss.append(epoch_val_loss / epoch_val_steps)\n",
    "        self.all_epoch_validation_steps.append(epoch_val_steps)\n",
    "        '''try:\n",
    "            np.save(os.path.join(self.storage_rl, 'q_validation_losses.npy'), np.array(self.all_epoch_validation_loss))\n",
    "        except:\n",
    "            pass'''\n",
    "\n",
    "    \n",
    "\n",
    "def train(params, rng, loader_train, loader_validation):\n",
    "    qnet = RL(state_dim=params[\"state_dim\"], rolling_size=params[\"rolling_size\"], nb_actions=params[\"num_actions\"], n_units=params[\"n_units\"], gamma=params[\"gamma\"], \n",
    "    learning_rate=params[\"learning_rate\"],update_freq=params[\"update_freq\"], rng=params[\"random_seed\"], device=params[\"device\"])\n",
    "    print('Initializing Experiment')\n",
    "    expt = DQNExperiment(data_loader_train=loader_train, data_loader_validation=loader_validation, q_network=qnet,\n",
    "                        saving_period=params[\"exp_saving_period\"], rng=rng)\n",
    "    '''with open(os.path.join(expt.storage_rl, 'config_exp.yaml'), 'w') as y:\n",
    "            yaml.safe_dump(params, y)  # saving new params for future reference'''\n",
    "    print('Running experiment (training Q-Networks)')\n",
    "    expt.do_epochs(number=params[\"exp_num_epochs\"])\n",
    "    print(\"Training Q-Networks finished successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    np.random.seed(params['random_seed'])\n",
    "    torch.manual_seed(params['random_seed'])\n",
    "    rng = np.random.RandomState(params['random_seed'])\n",
    "\n",
    "    loader_train, loader_validation = make_data_loaders(params['train'], params['val'], rng, params['device'],params['minibatch_size'],params['rolling_size'],type='discharge')\n",
    "    train(params, rng, loader_train, loader_validation)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

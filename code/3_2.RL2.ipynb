{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.getcwd()[-4:] == \"code\":\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./code/params.yaml\")) as f:\n",
    "        params = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet('./data/train.parquet')\n",
    "val_df.to_parquet('./data/val.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition(data,rolling_size,batch_size,shuffle):\n",
    "    df = pd.read_parquet(data)\n",
    "    s_col = [x for x in df if x[:2]=='s:']\n",
    "    a_col = [x for x in df if x[:2]=='a:']\n",
    "    r_col = [x for x in df if x[:2]=='r:']\n",
    "    dict = {}\n",
    "    dict['traj'] = {}\n",
    "    data_len = 0\n",
    "\n",
    "    s,a,r1,r2,r3,s2,t  = [],[],[],[],[],[],[]\n",
    "    \n",
    "    for traj in tqdm(df.traj.unique()):\n",
    "        df_traj = df[df['traj'] == traj]\n",
    "        dict['traj'][traj] = {'s':[],'a':[],'r1':[], 'r2':[],'r3':[]}\n",
    "        dict['traj'][traj]['s'] = df_traj[s_col].values.tolist()\n",
    "        dict['traj'][traj]['a'] = df_traj[a_col].values.tolist()\n",
    "        dict['traj'][traj]['r1'] = df_traj[r_col[0]].values.tolist()\n",
    "        dict['traj'][traj]['r2'] = df_traj[r_col[1]].values.tolist()\n",
    "        dict['traj'][traj]['r3'] = df_traj[r_col[2]].values.tolist()\n",
    "\n",
    "        step_len = len(df_traj) - rolling_size - 1\n",
    "        for step in range(step_len):\n",
    "            s.append(dict['traj'][traj]['s'][step:step+rolling_size])\n",
    "            a.append(dict['traj'][traj]['a'][step+rolling_size-1:step+rolling_size])\n",
    "            r1.append(dict['traj'][traj]['r1'][step+rolling_size-1])\n",
    "            r2.append(dict['traj'][traj]['r2'][step+rolling_size-1])\n",
    "            r3.append(dict['traj'][traj]['r3'][step+rolling_size-1])\n",
    "            s2.append(dict['traj'][traj]['s'][step+1:step+1+rolling_size])\n",
    "            t.append(0)\n",
    "            data_len += 1\n",
    "        s.append(dict['traj'][traj]['s'][step_len:step_len+rolling_size])\n",
    "        a.append(dict['traj'][traj]['a'][step_len+rolling_size-1:step_len+rolling_size])\n",
    "        r1.append(dict['traj'][traj]['r1'][step_len+rolling_size-1])\n",
    "        r2.append(dict['traj'][traj]['r2'][step_len+rolling_size-1])\n",
    "        r3.append(dict['traj'][traj]['r3'][step_len+rolling_size-1])\n",
    "        s2.append(dict['traj'][traj]['s'][step_len+1:step_len+1+rolling_size])\n",
    "        t.append(1)\n",
    "        data_len += 1\n",
    "    \n",
    "    s  = torch.FloatTensor(np.float32(s))\n",
    "    a  = torch.LongTensor(np.int64(a))\n",
    "    r1 = torch.FloatTensor(np.float32(r1))\n",
    "    r2 = torch.FloatTensor(np.float32(r2))\n",
    "    r3 = torch.FloatTensor(np.float32(r3))\n",
    "    s2 = torch.FloatTensor(np.float32(s2))\n",
    "    t  = torch.FloatTensor(np.float32(t))\n",
    "\n",
    "    rt = DataLoader(TensorDataset(s, a, r1, r2, r3, s2, t),batch_size,shuffle)\n",
    "    return rt, data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11569/11569 [00:27<00:00, 413.66it/s]\n",
      "100%|██████████| 771/771 [00:01<00:00, 760.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, train_len = make_transition(params['train'],rolling_size=24,batch_size=64,shuffle=True)\n",
    "val_loader, val_len = make_transition(params['val'],rolling_size=24,batch_size=256,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imvt(torch.jit.ScriptModule):\n",
    "    __constants__ = ['input_dim', 'n_units']\n",
    "    def __init__(self, input_dim, output_dim, n_units, device, init_std=0.02):\n",
    "        super().__init__()\n",
    "        self.U_j = nn.Parameter(torch.randn(input_dim, 1, n_units)*init_std)\n",
    "        self.U_i = nn.Parameter(torch.randn(input_dim, 1, n_units)*init_std)\n",
    "        self.U_f = nn.Parameter(torch.randn(input_dim, 1, n_units)*init_std)\n",
    "        self.U_o = nn.Parameter(torch.randn(input_dim, 1, n_units)*init_std)\n",
    "        self.W_j = nn.Parameter(torch.randn(input_dim, n_units, n_units)*init_std)\n",
    "        self.W_i = nn.Parameter(torch.randn(input_dim, n_units, n_units)*init_std)\n",
    "        self.W_f = nn.Parameter(torch.randn(input_dim, n_units, n_units)*init_std)\n",
    "        self.W_o = nn.Parameter(torch.randn(input_dim, n_units, n_units)*init_std)\n",
    "        self.b_j = nn.Parameter(torch.randn(input_dim, n_units)*init_std)\n",
    "        self.b_i = nn.Parameter(torch.randn(input_dim, n_units)*init_std)\n",
    "        self.b_f = nn.Parameter(torch.randn(input_dim, n_units)*init_std)\n",
    "        self.b_o = nn.Parameter(torch.randn(input_dim, n_units)*init_std)\n",
    "        self.F_alpha_n = nn.Parameter(torch.randn(input_dim, n_units, 1)*init_std)\n",
    "        self.F_alpha_n_b = nn.Parameter(torch.randn(input_dim, 1)*init_std)\n",
    "        self.F_beta = nn.Linear(2*n_units, 1)\n",
    "        self.Phi = nn.Linear(2*n_units, output_dim)\n",
    "        self.n_units = n_units\n",
    "        self.input_dim = input_dim\n",
    "        self.device = device\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        h_tilda_t = torch.zeros(x.shape[0], self.input_dim, self.n_units).to(self.device)\n",
    "        c_tilda_t = torch.zeros(x.shape[0], self.input_dim, self.n_units).to(self.device)\n",
    "        outputs = torch.jit.annotate(List[Tensor], [])\n",
    "        for t in range(x.shape[1]):\n",
    "            j_tilda_t = torch.tanh(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_j) + \\\n",
    "                                   torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_j) + self.b_j)\n",
    "            i_tilda_t = torch.sigmoid(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_i) + \\\n",
    "                                torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_i) + self.b_i)\n",
    "            f_tilda_t = torch.sigmoid(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_f) + \\\n",
    "                                torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_f) + self.b_f)\n",
    "            o_tilda_t = torch.sigmoid(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_o) + \\\n",
    "                                torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_o) + self.b_o)\n",
    "            c_tilda_t = c_tilda_t*f_tilda_t + i_tilda_t*j_tilda_t\n",
    "            h_tilda_t = (o_tilda_t*torch.tanh(c_tilda_t))\n",
    "            outputs += [h_tilda_t]\n",
    "        outputs = torch.stack(outputs)\n",
    "        outputs = outputs.permute(1, 0, 2, 3)\n",
    "        \n",
    "        alphas = torch.tanh(torch.einsum(\"btij,ijk->btik\", outputs, self.F_alpha_n)+self.F_alpha_n_b)\n",
    "        alphas = torch.exp(alphas)\n",
    "        alphas = alphas/torch.sum(alphas, dim=1, keepdim=True)\n",
    "        g_n = torch.sum(alphas*outputs, dim=1)\n",
    "        hg = torch.cat([g_n, h_tilda_t], dim=2)\n",
    "        mu = self.Phi(hg)\n",
    "        betas = torch.tanh(self.F_beta(hg))\n",
    "        betas = torch.exp(betas)\n",
    "        betas = betas/torch.sum(betas, dim=1, keepdim=True)\n",
    "        mean = torch.sum(betas*mu, dim=1)\n",
    "\n",
    "        return mean, alphas, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = params['device']\n",
    "#network = IMVFullLSTM(state_dim=params['state_dim'], nb_actions=params['num_actions'], n_units=params['n_units'], device=params['device']).to(device)\n",
    "#target_network = IMVFullLSTM(state_dim=params['state_dim'], nb_actions=params['num_actions'], n_units=params['n_units'], device=params['device']).to(device)\n",
    "#network = QNetwork(state_dim=params['state_dim'], rolling_size=1,nb_actions=12).to(device)\n",
    "#target_network = QNetwork(state_dim=params['state_dim'], rolling_size=1,nb_actions=12).to(device)\n",
    "network = imvt(params['state_dim'], params['num_actions'], n_units=32, device=params['device']).to(device)\n",
    "target_network = imvt(params['state_dim'], params['num_actions'], n_units=32, device=params['device']).to(device)\n",
    "\n",
    "epoch = 200\n",
    "gamma = 1.0\n",
    "optimizer = optim.Adam(network.parameters(), lr=params['learning_rate'], amsgrad=True)\n",
    "\n",
    "update_freq = 2\n",
    "\n",
    "for i in range(epoch):\n",
    "    loss_train = 0\n",
    "    update_counter = 0\n",
    "    for s,a,r1,r2,r3,s2,t in tqdm(train_loader):\n",
    "        s = s.to(device)\n",
    "        a = a.to(device)\n",
    "        r1 = r1.to(device)\n",
    "        r2 = r2.to(device)\n",
    "        r3 = r3.to(device)\n",
    "        s2 = s2.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        q,_,_ = network(s)\n",
    "        q2,_,_ = target_network(s2)\n",
    "        q2 = q2.detach()\n",
    "        q_pred = q.gather(1, a.squeeze(1)).squeeze()\n",
    "\n",
    "        q2_net, _, _ = network(s2)\n",
    "        q2_net = q2_net.detach()\n",
    "        q2_max = q2.gather(1, torch.max(q2_net,dim=1)[1].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        bellman_target = torch.clamp(r1, max=1.0, min=0.0) + gamma * torch.clamp(q2_max.detach(), max=1.0, min=0.0)*(1-t)\n",
    "        loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_train += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        update_counter += 1\n",
    "        if update_counter == update_freq:\n",
    "            target_network.load_state_dict(network.state_dict())\n",
    "            update_counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_val = 0\n",
    "\n",
    "        for s,a,r1,r2,r3,s2,t in val_loader:\n",
    "            s = s.to(device)\n",
    "            a = a.to(device)\n",
    "            r1 = r1.squeeze().to(device)\n",
    "            r2 = r2.squeeze().to(device)\n",
    "            r3 = r3.squeeze().to(device)\n",
    "            s2 = s2.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            q,_,_ = network(s)\n",
    "            q2,_,_ = target_network(s2)\n",
    "            q2 = q2.detach()\n",
    "            q_pred = q.gather(1, a.squeeze(1)).squeeze()\n",
    "\n",
    "            q2_net,_,_ = network(s2)\n",
    "            q2_net = q2_net.detach()\n",
    "            q2_max = q2.gather(1, torch.max(q2_net,dim=1)[1].unsqueeze(1)).squeeze()\n",
    "\n",
    "            bellman_target = torch.clamp(r1, max=1.0, min=0.0) + gamma * torch.clamp(q2_max.detach(), max=1.0, min=0.0)*(1-t)\n",
    "            loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "            loss_val += loss.item()\n",
    "\n",
    "    print(\"Iter: \", i, \"train: \",loss_train/train_len, \"val: \",loss_val/val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

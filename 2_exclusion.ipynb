{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, pickle, utils, math, tqdm\n",
    "\n",
    "from datetime import timedelta\n",
    "#from utils import baseline_SCr\n",
    "\n",
    "if os.getcwd()[-4:] == \"code\":\n",
    "    os.chdir('../')\n",
    "\n",
    "icu = './data/mimic-iv-2.2-parquet/icu/'\n",
    "hosp = './data/mimic-iv-2.2-parquet/hosp/'\n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None) # 경고 off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73181"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/resample/resample_label.parquet')\n",
    "len(df.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnss = pd.DataFrame(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['subject_id','hadm_id','stay_id','charttime'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57734"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24시간 이내 퇴원\n",
    "df = df.groupby('stay_id').filter(lambda x:len(x) > 24)\n",
    "len(df.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15459"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24시간 이내 AKI 발생\n",
    "\n",
    "# 각 stay_id에 대해 처음 24개 행을 선택\n",
    "first_24 = df.groupby('stay_id').head(24)\n",
    "\n",
    "# 'AKI' 지표가 1 이상인 행을 포함하는 stay_id를 제외\n",
    "filtered_df = first_24.groupby('stay_id').filter(lambda x: not (x['AKI'] >= 1).any())\n",
    "filtered_df = filtered_df.groupby('stay_id').filter(lambda x: not (x['dead'] >= 1).any())\n",
    "\n",
    "# 원래 DataFrame에서 필터링된 stay_id만 선택\n",
    "df = df[df['stay_id'].isin(filtered_df['stay_id'].unique())]\n",
    "\n",
    "len(df.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15246"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 stay_id별로 count_category가 3 이상인 경우의 개수 계산\n",
    "count_3_or_more = df.groupby('stay_id')['category_count'].transform(lambda x: (x >= 3).sum())\n",
    "\n",
    "# count_category가 3 이상인 경우가 없는 stay_id만 필터링\n",
    "df = df[count_3_or_more < 1]\n",
    "len(df.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15234"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['HR','SBP','DBP','MAP','temp','RR','weight'],inplace=True)\n",
    "len(df.stay_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action\n",
    "df.loc[df['category_count']==0, 'action'] = 0\n",
    "df.loc[(df['category_count']==1)&(df['Cephalosporins']==1), 'action'] = 1\n",
    "df.loc[(df['category_count']==1)&(df['Vancomycin']==1), 'action'] = 2\n",
    "df.loc[(df['category_count']==1)&(df['Betalactam_comb']==1), 'action'] = 3\n",
    "df.loc[(df['category_count']==1)&(df['Metronidazole']==1), 'action'] = 4\n",
    "df.loc[(df['category_count']==1)&(df['Carbapenems']==1), 'action'] = 5\n",
    "df.loc[(df['category_count']==1)&(df['Penicillins']==1), 'action'] = 6\n",
    "df.loc[(df['category_count']==1)&(df['Fluoroquinolones']==1), 'action'] = 7\n",
    "df.loc[(df['category_count']==1)&(df['Others']==1), 'action'] = 8\n",
    "\n",
    "df.loc[(df['category_count']==2), 'action'] = 11\n",
    "df.loc[(df['category_count']==2)&(df['Cephalosporins']==1)&(df['Vancomycin']==1), 'action'] = 9\n",
    "df.loc[(df['category_count']==2)&(df['Betalactam_comb']==1)&(df['Vancomycin']==1), 'action'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "0.0     1243904\n",
       "1.0       30142\n",
       "2.0       26248\n",
       "3.0       13116\n",
       "4.0        7815\n",
       "6.0        7290\n",
       "5.0        7152\n",
       "8.0        6107\n",
       "7.0        4638\n",
       "11.0       3680\n",
       "9.0        2034\n",
       "10.0        892\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.action.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAHS\\AppData\\Local\\Temp\\ipykernel_582692\\4198296411.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('stay_id').apply(process_group).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df['discharge'] = 0\n",
    "\n",
    "def process_group(group):\n",
    "    if group['dead'].sum() == 0:  # dead 열의 합이 0이면 모든 값이 0임\n",
    "        group.iloc[-1, group.columns.get_loc('discharge')] = 1  # 마지막 행의 discharge 값을 1로 설정\n",
    "    else:\n",
    "        first_dead_index = group['dead'].idxmax()  # dead 열에서 1이 처음으로 나타나는 인덱스\n",
    "        group = group.loc[:first_dead_index]  # 첫 번째 dead 이후의 행들을 제거\n",
    "    return group\n",
    "\n",
    "# stay_id별로 그룹화하고 각 그룹에 대해 process_group 함수 적용\n",
    "df = df.groupby('stay_id').apply(process_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['presense_SOFA'] = 1\n",
    "df.loc[df['SOFA'].isna(),'presense_SOFA'] = 0\n",
    "\n",
    "df['presense_BUN/SCr'] = 1\n",
    "df.loc[df['BUN/SCr'].isna(),'presense_BUN/SCr'] = 0\n",
    "\n",
    "df.loc[(df['presense_BUN']==0)|(df['presense_SCr']==0),'presense_BUN/SCr'] = 0\n",
    "df.loc[df['presense_BUN/SCr']==0,'BUN/SCr']=0\n",
    "\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['action']==0, 'action_0'] = 1\n",
    "df.loc[df['action']==1, 'action_1'] = 1\n",
    "df.loc[df['action']==2, 'action_2'] = 1\n",
    "df.loc[df['action']==3, 'action_3'] = 1\n",
    "df.loc[df['action']==4, 'action_4'] = 1\n",
    "df.loc[df['action']==5, 'action_5'] = 1\n",
    "df.loc[df['action']==6, 'action_6'] = 1\n",
    "df.loc[df['action']==7, 'action_7'] = 1\n",
    "df.loc[df['action']==8, 'action_8'] = 1\n",
    "df.loc[df['action']==9, 'action_9'] = 1\n",
    "df.loc[df['action']==10, 'action_10'] = 1\n",
    "df.loc[df['action']==11, 'action_11'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15234/15234 [01:10<00:00, 216.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def zeropadding(df):\n",
    "    rt = []\n",
    "    for i in tqdm(df.stay_id.unique()):\n",
    "        tmp = df[df['stay_id']==i]\n",
    "        endtime = tmp.charttime.min() - pd.Timedelta(hours=1)\n",
    "        starttime = endtime - pd.Timedelta(hours=23)\n",
    "        timestamp_range = pd.date_range(start=starttime,end=endtime,freq='h')\n",
    "\n",
    "        empty_df = pd.DataFrame({'stay_id':i, 'charttime':timestamp_range})\n",
    "        tmp = pd.concat([tmp,empty_df])\n",
    "        tmp.sort_values(by='charttime',inplace=True)\n",
    "        rt.append(tmp)\n",
    "    rt = pd.concat(rt)\n",
    "    rt.reset_index(inplace=True)\n",
    "    return rt\n",
    "df = zeropadding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['traj'] = pd.factorize(df['stay_id'])[0]\n",
    "df.sort_values(by=['traj','charttime'],inplace=True)\n",
    "df['step'] = df.groupby('stay_id').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adas2=pd.DataFrame(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['traj','step', 'age', 'gender','weight',\n",
    "       'WHITE', 'BLACK', 'HISPANIC OR LATINO', 'ASIAN', 'OTHER', 'UNKNOWN',\n",
    "       'LD', 'DH', 'HYP', 'CKD', 'MI', 'DM', 'VD', 'CHF', 'COPD', 'baseline_SCr',\n",
    "       'HR', 'SBP', 'DBP', 'MAP', 'temp', 'RR', 'CVP', 'SaO2', 'FiO2',\n",
    "\n",
    "       'Alb', 'Alk_Phos', 'AG', 'BUN', 'Ca', 'CK', 'D_Bil', 'Glu', 'HCT', 'INR', 'PH', 'PHOS',\n",
    "       'Platelet', 'Cl', 'SCr', 'Na', 'Potassium', 'T_Bil', 'WBC', 'Gl', 'Mg',\n",
    "       'Ca_ion', 'HCO3', 'AST', 'ALT', 'PTT', 'baseexcess', 'lactate','PaO2','PaCO2',\n",
    "       \n",
    "       'presense_HR', 'presense_SBP', 'presense_DBP', 'presense_MAP', 'presense_temp', 'presense_RR', 'presense_CVP', 'presense_SaO2', 'presense_FiO2',\n",
    "       'presense_Alb', 'presense_Alk_Phos', 'presense_AG', 'presense_BUN', 'presense_Ca', 'presense_CK', 'presense_D_Bil', 'presense_Glu', 'presense_HCT', 'presense_INR', 'presense_PH', 'presense_PHOS',\n",
    "       'presense_Platelet', 'presense_Cl', 'presense_SCr', 'presense_Na', 'presense_Potassium', 'presense_T_Bil', 'presense_WBC', 'presense_Gl', 'presense_Mg',\n",
    "       'presense_Ca_ion', 'presense_HCO3', 'presense_AST', 'presense_ALT', 'presense_PTT', 'presense_baseexcess', 'presense_lactate','presense_PaO2','presense_PaCO2',\n",
    "       'presense_SOFA', 'presense_BUN/SCr','presense_AKI_UO','presense_AKI_SCr','presense_AKI',\n",
    "              \n",
    "       'uo', 'SOFA', 'AKI_UO', 'AKI_SCr', 'AKI', 'ventilation', 'fluid', 'vaso_equ',\n",
    "       'SCr/baseline_SCr', 'delta_SCr', 'BUN/SCr', \n",
    "       'action_0','action_1','action_2','action_3','action_4','action_5','action_6','action_7','action_8','action_9','action_10','action_11',\n",
    "       'action','dead','discharge','AKI_stage3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col =['age', 'gender','weight',\n",
    "       'WHITE', 'BLACK', 'HISPANIC OR LATINO', 'ASIAN', 'OTHER', 'UNKNOWN',\n",
    "       'LD', 'DH', 'HYP', 'CKD', 'MI', 'DM', 'VD', 'CHF', 'COPD', 'baseline_SCr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col] = df.groupby('traj')[col].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15234"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.traj.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dead_aki: 172 dead_nonaki: 337 surv_aki: 1161 surv_nonaki: 13564\n",
      "==============================\n",
      "train_df: 1278324 val_df: 88932 test_df: 347715\n",
      "train_df.traj.unique(): 11426 val_df.traj.unique(): 762 test_df.traj.unique(): 3046\n"
     ]
    }
   ],
   "source": [
    "def make_train_val_test_split(df, train_frac=0.75, val_frac=0.05):\n",
    "    all_traj = df['traj'].unique()\n",
    "    all_AKI = []\n",
    "    all_dead = []\n",
    "    for traj in all_traj:\n",
    "        aki = df[df['traj'] == traj]['AKI_stage3'].sum()\n",
    "        dead = df[df['traj'] == traj]['dead'].sum()\n",
    "        all_AKI.append(aki)\n",
    "        all_dead.append(dead)\n",
    "    dead_aki    = [x for x in range(len(all_traj)) if (all_AKI[x] > 0)&(all_dead[x] > 0)]\n",
    "    dead_nonaki = [x for x in range(len(all_traj)) if (all_AKI[x] == 0)&(all_dead[x] > 0)]\n",
    "    surv_aki    = [x for x in range(len(all_traj)) if (all_AKI[x] > 0)&(all_dead[x] == 0)]\n",
    "    surv_nonaki = [x for x in range(len(all_traj)) if (all_AKI[x] == 0)&(all_dead[x] == 0)]\n",
    "\n",
    "    print(\"dead_aki:\",len(dead_aki),\"dead_nonaki:\",len(dead_nonaki),\"surv_aki:\",len(surv_aki),\"surv_nonaki:\",len(surv_nonaki))\n",
    "\n",
    "    np.random.shuffle(dead_aki)\n",
    "    np.random.shuffle(dead_nonaki)\n",
    "    np.random.shuffle(surv_aki)\n",
    "    np.random.shuffle(surv_nonaki)\n",
    "\n",
    "    train_dead_aki_index    = int(np.round(train_frac*len(dead_aki),0))\n",
    "    train_dead_nonaki_index = int(np.round(train_frac*len(dead_nonaki),0))\n",
    "    train_surv_aki_index    = int(np.round(train_frac*len(surv_aki),0))\n",
    "    train_surv_nonaki_index = int(np.round(train_frac*len(surv_nonaki),0))\n",
    "\n",
    "    val_dead_aki_index      = int(np.round(val_frac*len(dead_aki),0)) + train_dead_aki_index\n",
    "    val_dead_nonaki_index   = int(np.round(val_frac*len(dead_nonaki),0)) + train_dead_nonaki_index\n",
    "    val_surv_aki_index      = int(np.round(val_frac*len(surv_aki),0)) + train_surv_aki_index\n",
    "    val_surv_nonaki_index   = int(np.round(val_frac*len(surv_nonaki),0)) + train_surv_nonaki_index\n",
    "\n",
    "    train_traj = dead_aki[:train_dead_aki_index]\n",
    "    train_traj.extend(dead_nonaki[:train_dead_nonaki_index])\n",
    "    train_traj.extend(surv_aki[:train_surv_aki_index])\n",
    "    train_traj.extend(surv_nonaki[:train_surv_nonaki_index])\n",
    "\n",
    "    val_traj = dead_aki[train_dead_aki_index:val_dead_aki_index]\n",
    "    val_traj.extend(dead_nonaki[train_dead_nonaki_index:val_dead_nonaki_index])\n",
    "    val_traj.extend(surv_aki[train_surv_aki_index:val_surv_aki_index])\n",
    "    val_traj.extend(surv_nonaki[train_surv_nonaki_index:val_surv_nonaki_index])\n",
    "\n",
    "    test_traj = dead_aki[val_dead_aki_index:]\n",
    "    test_traj.extend(dead_nonaki[val_dead_nonaki_index:])\n",
    "    test_traj.extend(surv_aki[val_surv_aki_index:])\n",
    "    test_traj.extend(surv_nonaki[val_surv_nonaki_index:])\n",
    "\n",
    "    train_df = df[df['traj'].isin(train_traj)]\n",
    "    val_df   = df[df['traj'].isin(val_traj)]\n",
    "    test_df  = df[df['traj'].isin(test_traj)]\n",
    "\n",
    "    print('==============================')\n",
    "    print(\"train_df:\",len(train_df), \"val_df:\",len(val_df), \"test_df:\",len(test_df))\n",
    "    print(\"train_df.traj.unique():\",len(train_df.traj.unique()), \"val_df.traj.unique():\",len(val_df.traj.unique()), \"test_df.traj.unique():\",len(test_df.traj.unique()))\n",
    "\n",
    "    \n",
    "    #train_df.to_parquet('./data/train.parquet')\n",
    "    #val_df.to_parquet('./data/val.parquet')\n",
    "    #test_df.to_parquet('./data/test.parquet')\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = make_train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_columns(df):\n",
    "    for i,idx in enumerate(df.columns):\n",
    "        if i < 2 : \n",
    "            pass\n",
    "        elif i >= 2 and i < len(df.columns) - 4 : \n",
    "            df[idx] = (df[idx]-df[idx].min())/(df[idx].max()-df[idx].min())\n",
    "            df.rename(columns={idx:'s:'+idx},inplace=True)            \n",
    "        elif idx == 'action': \n",
    "            df.rename(columns={idx:'a:'+idx},inplace=True)\n",
    "        else : \n",
    "            df.rename(columns={idx:'r:'+idx},inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = change_columns(train_df)\n",
    "val_df = change_columns(val_df)\n",
    "test_df = change_columns(test_df)\n",
    "\n",
    "#train_df.to_parquet('./code/train.parquet')\n",
    "#val_df.to_parquet('./code/val.parquet')\n",
    "#test_df.to_parquet('./code/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum().sum()\n",
    "val_df.isna().sum().sum()\n",
    "test_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.DataFrame([x for x in train_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pd.DataFrame([x for x in train_df.columns if x[:2]=='s:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in train_df.columns if x[:2]=='s:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet('./code/train.parquet')\n",
    "val_df.to_parquet('./code/val.parquet')\n",
    "test_df.to_parquet('./code/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
